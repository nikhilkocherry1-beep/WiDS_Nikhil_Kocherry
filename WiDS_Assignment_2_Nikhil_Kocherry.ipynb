{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e57f8e19-c2c1-4f56-946f-ee441b8aa0b8",
   "metadata": {},
   "source": [
    "# WiDS Week 2 Project - Nikhil Kocherry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "696918ce-72fd-4642-ac07-1775e135a8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/keras/src/export/tf2onnx_lib.py:8: FutureWarning: In the future `np.object` will be defined as the corresponding NumPy scalar.\n",
      "  if not hasattr(np, \"object\"):\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import itertools\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "import yfinance as yf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from scalecast.Forecaster import Forecaster\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80f45cd7-8d61-4029-91de-9b4feb8d072a",
   "metadata": {},
   "source": [
    "## 1. Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bb75b0-2025-4d4e-abb5-a571b01cd0ec",
   "metadata": {},
   "source": [
    "I imported stock information of 'AAPL' from yfinance (just as was done in the previous project)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e70d91e-ea17-42ef-8976-a4633b929449",
   "metadata": {},
   "source": [
    "## 2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55ca6dd7-a4a0-4e0f-b153-23e5add9af2c",
   "metadata": {},
   "source": [
    "I used the exact same approach as in the previous project. The test-train split has been done seaparately for both models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36e84a23-f70a-4636-870e-e74abf5bf7ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n",
      "\n",
      "1 Failed download:\n",
      "['AAPL']: SSLError('Failed to perform, curl: (35) Recv failure: Connection reset by peer. See https://curl.se/libcurl/c/libcurl-errors.html first for more details.')\n"
     ]
    }
   ],
   "source": [
    "dat = yf.download(\"AAPL\",period = \"max\", progress = \"False\")\n",
    "dat.columns = dat.columns.droplevel(1)\n",
    "dat = dat.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400767db-1607-4b00-ae9c-ac21ff676d85",
   "metadata": {},
   "source": [
    "## 3. ARIMA Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59aeae54-60e2-4752-8076-0f20a14f2f41",
   "metadata": {},
   "source": [
    "This is an exact copy of last project, barring the creation of a Forecaster object 'f', in order to compare both the models better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38cffd41-7723-46ac-b3cc-b16ec99893b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Need at least 3 dates to infer frequency",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m f = \u001b[43mForecaster\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdat\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mClose\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43mcurrent_dates\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mdat\u001b[49m\u001b[43m.\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m f.set_test_length(\u001b[32m0.2\u001b[39m)\n\u001b[32m      4\u001b[39m p = \u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, \u001b[32m4\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scalecast/Forecaster.py:104\u001b[39m, in \u001b[36mForecaster.__init__\u001b[39m\u001b[34m(self, y, current_dates, future_dates, test_length, cis, metrics, carry_fit_models, **kwargs)\u001b[39m\n\u001b[32m    102\u001b[39m \u001b[38;5;28mself\u001b[39m.grids_file = \u001b[33m'\u001b[39m\u001b[33mGrids\u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    103\u001b[39m \u001b[38;5;28mself\u001b[39m.carry_fit_models = carry_fit_models\n\u001b[32m--> \u001b[39m\u001b[32m104\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_typ_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# ensures that the passed values are the right types\u001b[39;00m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m future_dates \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    106\u001b[39m     \u001b[38;5;28mself\u001b[39m.generate_future_dates(future_dates)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scalecast/Forecaster.py:1365\u001b[39m, in \u001b[36mForecaster._typ_set\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1353\u001b[39m     _developer_utils.descriptive_assert(\n\u001b[32m   1354\u001b[39m         \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.current_xreg[k]) == \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.y),\n\u001b[32m   1355\u001b[39m         ForecastError,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1361\u001b[39m         ),\n\u001b[32m   1362\u001b[39m     )\n\u001b[32m   1363\u001b[39m     \u001b[38;5;28mself\u001b[39m.future_xreg[k] = [\u001b[38;5;28mfloat\u001b[39m(x) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.future_xreg[k]]\n\u001b[32m-> \u001b[39m\u001b[32m1365\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minfer_freq\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/scalecast/Forecaster.py:1333\u001b[39m, in \u001b[36mForecaster.infer_freq\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1330\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\" Uses the pandas library to infer the frequency of the loaded dates.\u001b[39;00m\n\u001b[32m   1331\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1332\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mfreq\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1333\u001b[39m     \u001b[38;5;28mself\u001b[39m.freq = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfer_freq\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcurrent_dates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1334\u001b[39m     \u001b[38;5;28mself\u001b[39m.current_dates.freq = \u001b[38;5;28mself\u001b[39m.freq\n\u001b[32m   1335\u001b[39m     \u001b[38;5;28mself\u001b[39m.future_dates.freq = \u001b[38;5;28mself\u001b[39m.freq\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/tseries/frequencies.py:155\u001b[39m, in \u001b[36minfer_freq\u001b[39m\u001b[34m(index)\u001b[39m\n\u001b[32m    152\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(index, DatetimeIndex):\n\u001b[32m    153\u001b[39m     index = DatetimeIndex(index)\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m inferer = \u001b[43m_FrequencyInferer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m inferer.get_freq()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/Library/Frameworks/Python.framework/Versions/3.12/lib/python3.12/site-packages/pandas/tseries/frequencies.py:189\u001b[39m, in \u001b[36m_FrequencyInferer.__init__\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m    184\u001b[39m         \u001b[38;5;28mself\u001b[39m.i8values = tz_convert_from_utc(\n\u001b[32m    185\u001b[39m             \u001b[38;5;28mself\u001b[39m.i8values, index.tz, reso=\u001b[38;5;28mself\u001b[39m._creso\n\u001b[32m    186\u001b[39m         )\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(index) < \u001b[32m3\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m189\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNeed at least 3 dates to infer frequency\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    191\u001b[39m \u001b[38;5;28mself\u001b[39m.is_monotonic = (\n\u001b[32m    192\u001b[39m     \u001b[38;5;28mself\u001b[39m.index._is_monotonic_increasing \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m.index._is_monotonic_decreasing\n\u001b[32m    193\u001b[39m )\n",
      "\u001b[31mValueError\u001b[39m: Need at least 3 dates to infer frequency"
     ]
    }
   ],
   "source": [
    "f = Forecaster(y = dat['Close'],current_dates = dat.index)\n",
    "f.set_test_length(0.2)\n",
    "\n",
    "p = range(0, 4)\n",
    "d = range(0, 3)\n",
    "q = range(0, 4)\n",
    "pdq = list(itertools.product(p, d, q))\n",
    "\n",
    "best_aic = np.inf\n",
    "best_order = None\n",
    "best_model = None\n",
    "\n",
    "for order in pdq:\n",
    "    try:\n",
    "        model = ARIMA(f, order=order)\n",
    "        results = model.fit()\n",
    "        if results.aic < best_aic:\n",
    "            best_aic = results.aic\n",
    "            best_order = order\n",
    "            best_model = results\n",
    "    except:\n",
    "        continue\n",
    "        \n",
    "f.set_estimator('arima',order = best_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad07c4f-bb50-482c-87a8-7ad435e69aa1",
   "metadata": {},
   "source": [
    "## 4. LSTM Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd0670a-2495-48df-bc82-560c2679779a",
   "metadata": {},
   "source": [
    "We are registering the LSTM model to the Forecaster object using the manual_forecast() function, as this estimator is not pre-defined in ScaleCast."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0face2-10b8-427a-9510-58f91106ec0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.manual_forecast(\n",
    "    call_me='lstm_best',\n",
    "    lags=36,\n",
    "    batch_size=32,\n",
    "    epochs=15,\n",
    "    validation_split = 0.2\n",
    "    shuffle = False\n",
    "    activation='tanh',\n",
    "    optimizer='Adam',\n",
    "    learning_rate=0.001,\n",
    "    lstm_layer_sizes=(72,)*4,\n",
    "    dropout=(0,)*4,\n",
    "    plot_loss=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6874d999-cc28-4390-aa1b-e9abc4c08855",
   "metadata": {},
   "source": [
    "Both the models are now fitted to the time series stored in the Forecaster object 'f', and the results of the models are plotted against the actual prices of the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46737166-5285-40e3-9e6c-76ec1c619c8a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'f' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mf\u001b[49m.fit()\n\u001b[32m      2\u001b[39m f.predict()\n\u001b[32m      3\u001b[39m f.plot(models = [\u001b[33m'\u001b[39m\u001b[33marima\u001b[39m\u001b[33m'\u001b[39m,\u001b[33m'\u001b[39m\u001b[33mlstm_best\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'f' is not defined"
     ]
    }
   ],
   "source": [
    "f.fit()\n",
    "f.predict()\n",
    "f.plot(models = ['arima','lstm_best'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e931e86-bf95-431a-979e-d5f6d30ea376",
   "metadata": {},
   "source": [
    "## 5. Comparison of ARIMA and LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0616842f-1b0b-4ac0-82b0-bd88f0aa9a32",
   "metadata": {},
   "source": [
    "The following statement gives us all the required error data of the two models, i.e. Mean Absolute Error, Root Mean absolute Error, and Mean Abspolute Percentage Error, in the form of a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b2b9bc-2244-4762-9fe4-0d7a4c235941",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ffddcfa-0375-4cbc-8faf-4201186727a6",
   "metadata": {},
   "source": [
    "## 7. Residual Comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fde4973-2e8f-4052-84fd-b9d52111e400",
   "metadata": {},
   "source": [
    "The following statements give us the plot of the error of the two models, in the form of their residue plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cda69a-e10a-4210-8282-91ca250c7b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "f.plot(f.y_test - f.forecasts['arima']['forecast'] , label = 'ARIMA_Residual')\n",
    "f.plot(f.y_test - f.forecasts['lstm_best']['forecast'] , label = 'LSTM_Residual')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b82f6740-5fad-45e2-9dae-2063824f19ab",
   "metadata": {},
   "source": [
    "# And the concludes the Assignment for Week 2!!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
